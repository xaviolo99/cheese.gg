{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPchampId</th>\n",
       "      <th>TOPkeyRune</th>\n",
       "      <th>TOPspell1</th>\n",
       "      <th>TOPspell2</th>\n",
       "      <th>JNGchampId</th>\n",
       "      <th>JNGkeyRune</th>\n",
       "      <th>JNGspell1</th>\n",
       "      <th>JNGspell2</th>\n",
       "      <th>MIDchampId</th>\n",
       "      <th>MIDkeyRune</th>\n",
       "      <th>MIDspell1</th>\n",
       "      <th>MIDspell2</th>\n",
       "      <th>ADCchampId</th>\n",
       "      <th>ADCkeyRune</th>\n",
       "      <th>ADCspell1</th>\n",
       "      <th>ADCspell2</th>\n",
       "      <th>SUPchampId</th>\n",
       "      <th>SUPkeyRune</th>\n",
       "      <th>SUPspell1</th>\n",
       "      <th>SUPspell2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>131</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOPchampId  TOPkeyRune  TOPspell1  TOPspell2  JNGchampId  JNGkeyRune  \\\n",
       "0          58           2          4          0          80          15   \n",
       "1          19           2          4          0          54           4   \n",
       "2         116           2          4          0          79           1   \n",
       "3         112          13          4          9          97           4   \n",
       "4          72           4          4          5          97           4   \n",
       "\n",
       "   JNGspell1  JNGspell2  MIDchampId  MIDkeyRune  MIDspell1  MIDspell2  \\\n",
       "0          4          9         131           8          4          7   \n",
       "1          4          9         136           4          4          5   \n",
       "2          4          9          51           4          4          0   \n",
       "3          5          9          82           7          4          7   \n",
       "4          5          9          60           4          4          5   \n",
       "\n",
       "   ADCchampId  ADCkeyRune  ADCspell1  ADCspell2  SUPchampId  SUPkeyRune  \\\n",
       "0         123          14          4          0         113          14   \n",
       "1         106           9          4          0          86          14   \n",
       "2         122           3          4          7          75           7   \n",
       "3          45           3          4          7          10           4   \n",
       "4          46           3          4          7         105           7   \n",
       "\n",
       "   SUPspell1  SUPspell2  \n",
       "0          4          5  \n",
       "1          4          5  \n",
       "2          4          5  \n",
       "3          4          5  \n",
       "4          4          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "table = pd.read_csv(\"positionData.csv\", low_memory=False)\n",
    "display(table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data extracting x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.79 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import itertools\n",
    "\n",
    "b = time.time()\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "array = table.values[:len(table)]\n",
    "\n",
    "i = np.arange(len(table))\n",
    "\n",
    "np.random.shuffle(array)\n",
    "\n",
    "#1st position, 2nd game, 3rd parameter, but then transposed\n",
    "x_cac = np.array([array[np.ix_(i,range(4))], \n",
    "                  array[np.ix_(i,range(4, 8))], \n",
    "                  array[np.ix_(i,range(8, 12))], \n",
    "                  array[np.ix_(i,range(12, 16))], \n",
    "                  array[np.ix_(i,range(16, 20))]]).transpose(1, 0, 2)\n",
    "y_cac = np.array([[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1]])\n",
    "\n",
    "perms = np.array(list(itertools.permutations([0, 1, 2, 3, 4])))\n",
    "\n",
    "e = np.arange(5)\n",
    "perm = np.arange(len(perms))\n",
    "\n",
    "#GO\n",
    "\n",
    "x_train = np.zeros((int(len(array)*train_ratio), 5, 4))\n",
    "y_train = np.zeros((int(len(array)*train_ratio), 5, 5))\n",
    "\n",
    "for i in range(int(len(array)*train_ratio)):\n",
    "    \n",
    "    x_train[i] = x_cac[i]\n",
    "    y_train[i] = y_cac\n",
    "\n",
    "x_test = np.zeros((int(len(array)*(1-train_ratio)), 5, 4))\n",
    "y_test = np.zeros((int(len(array)*(1-train_ratio)), 5, 5))\n",
    "\n",
    "for i in range(int(len(array)*(1-train_ratio))):\n",
    "    \n",
    "    x_test[i] = x_cac[i+int(len(array)*train_ratio)]\n",
    "    y_test[i] = y_cac\n",
    "\n",
    "print(\"Execution time:\", round(time.time()-b, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the data and check it is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55.   7.   4.   0.]\n",
      " [115.   0.   4.   9.]\n",
      " [  8.   9.   4.   1.]\n",
      " [106.   9.   4.   0.]\n",
      " [ 12.   8.   4.   5.]]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "x_train, y_train = unison_shuffled_copies(x_train, y_train)\n",
    "x_test, y_test = unison_shuffled_copies(x_test, y_test)\n",
    "\n",
    "print(x_train[-1])\n",
    "print(y_train[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the loaders and separate training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "bs = 64\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=bs, shuffle=True, num_workers=0)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klein\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:117: UserWarning: \n",
      "    Found GPU0 GeForce GTX 770 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (dropEmb): Dropout(p=0.05)\n",
       "  (dropLoc): Dropout(p=0.2)\n",
       "  (dropHid): Dropout(p=0.15)\n",
       "  (idC): Linear(in_features=141, out_features=70, bias=True)\n",
       "  (runeC): Linear(in_features=17, out_features=14, bias=True)\n",
       "  (spellsC): Linear(in_features=10, out_features=14, bias=True)\n",
       "  (c): Linear(in_features=98, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=450, bias=True)\n",
       "  (fc3): Linear(in_features=450, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.i = torch.arange(5).view(1, 5).to(device)\n",
    "        \n",
    "        self.id = torch.zeros(5, bs, 141).to(device)\n",
    "        self.rune = torch.zeros(5, bs, 17).to(device)\n",
    "        self.spells = torch.zeros(5, bs, 10).to(device)\n",
    "        \n",
    "        self.dropEmb = nn.Dropout(p=0.05).train()\n",
    "        self.dropLoc = nn.Dropout(p=0.2).train()\n",
    "        self.dropHid = nn.Dropout(p=0.15).train()\n",
    "        \n",
    "        self.idC = nn.Linear(141, 70) #50 best\n",
    "        self.runeC = nn.Linear(17, 14) #9 best\n",
    "        self.spellsC = nn.Linear(10, 14)#10 best\n",
    "        \n",
    "        self.c = nn.Linear(70+14+14, 100) #40 best\n",
    "        \n",
    "        self.fc2 = nn.Linear((100)*5, 450) #40, 200 best\n",
    "        self.fc3 = nn.Linear(450, 25) #200 best\n",
    "        #self.fc4 = nn.Linear(400, 25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.id.zero_()\n",
    "        self.rune.zero_()\n",
    "        self.spells.zero_()\n",
    "        \n",
    "        k1 = x[:, self.i*4].long().transpose(0, 2).view(5, bs, 1)\n",
    "        k2 = x[:, self.i*4+1].long().transpose(0, 2).view(5, bs, 1)\n",
    "        k3 = x[:, self.i*4+2].long().transpose(0, 2).view(5, bs, 1)\n",
    "        k4 = x[:, self.i*4+3].long().transpose(0, 2).view(5, bs, 1)\n",
    "        \n",
    "        self.id.scatter_(2, k1, 1)\n",
    "        self.rune.scatter_(2, k2, 1)\n",
    "        self.spells.scatter_(2, k3, 1)\n",
    "        self.spells.scatter_(2, k4, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        x = torch.cat((\n",
    "            self.dropLoc(F.relu(self.c(torch.cat((\n",
    "                self.dropEmb(F.relu(self.idC(self.id[0]))), \n",
    "                self.dropEmb(F.relu(self.runeC(self.rune[0]))), \n",
    "                self.dropEmb(F.relu(self.spellsC(self.spells[0])))\n",
    "                ), dim=1)))),\n",
    "            self.dropLoc(F.relu(self.c(torch.cat((\n",
    "                self.dropEmb(F.relu(self.idC(self.id[1]))), \n",
    "                self.dropEmb(F.relu(self.runeC(self.rune[1]))), \n",
    "                self.dropEmb(F.relu(self.spellsC(self.spells[1])))\n",
    "            ), dim=1)))),\n",
    "            self.dropLoc(F.relu(self.c(torch.cat((\n",
    "                self.dropEmb(F.relu(self.idC(self.id[2]))), \n",
    "                self.dropEmb(F.relu(self.runeC(self.rune[2]))), \n",
    "                self.dropEmb(F.relu(self.spellsC(self.spells[2])))\n",
    "            ), dim=1)))),\n",
    "            self.dropLoc(F.relu(self.c(torch.cat((\n",
    "                self.dropEmb(F.relu(self.idC(self.id[3]))), \n",
    "                self.dropEmb(F.relu(self.runeC(self.rune[3]))), \n",
    "                self.dropEmb(F.relu(self.spellsC(self.spells[3])))\n",
    "            ), dim=1)))),\n",
    "            self.dropLoc(F.relu(self.c(torch.cat((\n",
    "                self.dropEmb(F.relu(self.idC(self.id[4]))), \n",
    "                self.dropEmb(F.relu(self.runeC(self.rune[4]))), \n",
    "                self.dropEmb(F.relu(self.spellsC(self.spells[4])))\n",
    "            ), dim=1))))\n",
    "            ), dim=1)\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        x = torch.cat((\n",
    "            F.relu(self.c(torch.cat((\n",
    "                F.relu(self.idC(self.id[0])), \n",
    "                F.relu(self.runeC(self.rune[0])), \n",
    "                F.relu(self.spellsC(self.spells[0]))\n",
    "                ), dim=1))),\n",
    "            F.relu(self.c(torch.cat((\n",
    "                F.relu(self.idC(self.id[1])), \n",
    "                F.relu(self.runeC(self.rune[1])), \n",
    "                F.relu(self.spellsC(self.spells[1]))\n",
    "            ), dim=1))),\n",
    "            F.relu(self.c(torch.cat((\n",
    "                F.relu(self.idC(self.id[2])), \n",
    "                F.relu(self.runeC(self.rune[2])), \n",
    "                F.relu(self.spellsC(self.spells[2]))\n",
    "            ), dim=1))),\n",
    "            F.relu(self.c(torch.cat((\n",
    "                F.relu(self.idC(self.id[3])), \n",
    "                F.relu(self.runeC(self.rune[3])), \n",
    "                F.relu(self.spellsC(self.spells[3]))\n",
    "            ), dim=1))),\n",
    "            F.relu(self.c(torch.cat((\n",
    "                F.relu(self.idC(self.id[4])), \n",
    "                F.relu(self.runeC(self.rune[4])), \n",
    "                F.relu(self.spellsC(self.spells[4]))\n",
    "            ), dim=1)))\n",
    "        ), dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #x = self.dropHid(F.relu(self.fc2(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a loss function and a optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.2, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), amsgrad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klein\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1101: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 0.345\n",
      "[1,   400] loss: 0.072\n",
      "[1,   600] loss: 0.056\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6c57c0c828af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perms = np.array(list(itertools.permutations([0, 1, 2, 3, 4])))\n",
    "marker = ( np.ones((bs, 5)) * np.array([np.arange(bs)]).T ).astype(\"int\")\n",
    "#deflab = torch.from_numpy(np.ones((64, 5, 5)) * np.array([[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 1, 0, 0], [0, 0, 0, 1, 0], [0, 0, 0, 0, 1]]))\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    \n",
    "    testiter = iter(testloader)\n",
    "    running_loss = 0.0 # mean loss in the 2000 batches between printing and printing\n",
    "    bTime = time.time()\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs and randomize them\n",
    "        inputs, labels = data\n",
    "        idx = np.random.randint(len(perms), size=64)\n",
    "        inputs = inputs[marker, perms[idx]].view(bs, 20)\n",
    "        labels = labels[marker, perms[idx]].view(bs, 25)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 100 mini-batches\n",
    "            #print(time.time()-bTime, \"iter\")\n",
    "            #bTime = time.time()\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        if i % 2000 == 1999:\n",
    "            lossc = 0\n",
    "            count = 0\n",
    "            net.train(False)\n",
    "            for j, data2 in enumerate(testloader, 0):\n",
    "                images, labels = data2\n",
    "                idx = np.random.randint(len(perms), size=64)\n",
    "                images = images[marker, perms[idx]].view(bs, 20)\n",
    "                labels = labels[marker, perms[idx]].view(bs, 25)\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = net(images)\n",
    "                lossc += F.binary_cross_entropy(outputs, labels.float()).item()\n",
    "                count += 1\n",
    "                if j == len(testloader)-2:\n",
    "                    break\n",
    "            print('test loss: '+str(round(lossc/count, 4)))\n",
    "            net.train(True)\n",
    "            \n",
    "        if i == len(trainloader)-2:\n",
    "            break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\torch\\nn\\functional.py:1025: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.03263\n",
      "5 correct: 92.55%\n",
      "4 correct: 1.86%\n",
      "3 correct: 5.18%\n",
      "2 correct: 0.38%\n",
      "1 correct: 0.02%\n",
      "0 correct: 0.0%\n"
     ]
    }
   ],
   "source": [
    "lossc = 0\n",
    "correct = torch.zeros(6).to(device)\n",
    "cache = torch.zeros(bs).to(device).long()\n",
    "count = 0\n",
    "\n",
    "bTime = time.time()\n",
    "\n",
    "net.train(False)\n",
    "\n",
    "for j, data in enumerate(testloader, 0):\n",
    "    images, labels = data\n",
    "    idx = np.random.randint(len(perms), size=64)\n",
    "    images = images[marker, perms[idx]].view(bs, 20)\n",
    "    labels = labels[marker, perms[idx]].view(bs, 25)\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    \n",
    "    lossc += F.binary_cross_entropy(outputs, labels.float()).item()\n",
    "    \n",
    "    cache.zero_()\n",
    "    \n",
    "    #labels = labels.contiguous().view(bs, 5, 5).transpose(1, 2).contiguous().view(bs, 25)\n",
    "    #outputs = outputs.contiguous().view(bs, 5, 5).transpose(1, 2).contiguous().view(bs, 25)\n",
    "    \n",
    "    for i in np.arange(0, 25, 5):\n",
    "        cache += (torch.argmax(outputs[:, i:i+5], 1) == torch.argmax(labels[:, i:i+5], 1)).long()\n",
    "    \n",
    "    correct += torch.bincount(cache).float()\n",
    "        \n",
    "    count += 1\n",
    "    \n",
    "    #print(outputs.view(bs, 5, 5))\n",
    "    #\n",
    "    \n",
    "    if j == len(testloader)-2:\n",
    "        break\n",
    "    \n",
    "net.train(True)\n",
    "\n",
    "print('loss: '+str(round(lossc/count, 5)))\n",
    "print('5 correct: '+str(round(correct[5].item()/(count*bs)*100, 2))+'%')\n",
    "print('4 correct: '+str(round(correct[4].item()/(count*bs)*100, 2))+'%')\n",
    "print('3 correct: '+str(round(correct[3].item()/(count*bs)*100, 2))+'%')\n",
    "print('2 correct: '+str(round(correct[2].item()/(count*bs)*100, 2))+'%')\n",
    "print('1 correct: '+str(round(correct[1].item()/(count*bs)*100, 2))+'%')\n",
    "print('0 correct: '+str(round(correct[0].item()/(count*bs)*100, 2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('92.55', 'wb') as fp:\n",
    "    pickle.dump(list(net.parameters()), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), '92.55.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
